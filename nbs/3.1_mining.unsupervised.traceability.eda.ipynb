{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mining.unsupervised.traceability.eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Software Traceability [EDA]\n",
    "> Adapted from CodeSearchNet Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth',300)\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "columns_short_list = ['code_tokens', 'docstring_tokens', \n",
    "                      'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def valid_register(code):\n",
    "    '''print(code)\n",
    "    print(type(code))'''\n",
    "    return type(code) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_valid_code_df(code_df, column):\n",
    "    return code_df[code_df[column].apply(valid_register)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastprogress'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b0df940656e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# ds4se\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mds4se\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgmnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mds4se\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mds4se\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ds4se-0.0.1-py3.8.egg/ds4se/mgmnt/prep/bpe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentencepiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastprogress\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtokenizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mByteLevelBPETokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastprogress'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "# Imports\n",
    "import dit\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sentencepiece as sp\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from scipy.stats import sem, t\n",
    "from statistics import mean, median, stdev\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ds4se\n",
    "from ds4se.mgmnt.prep.bpe import *\n",
    "from ds4se.exp.info import *\n",
    "from ds4se.desc.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ds4se.desc.metrics import *\n",
    "from ds4se.desc.metrics.java import *\n",
    "import lizard\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_method_mccabe_metrics_to_code_df(src_code_df, code_column):\n",
    "    \"\"\"Computes method level McAbe metrics and adds it as columns in the specified dataframe\"\"\"\n",
    "    #result_df = src_code_df.copy()\n",
    "    cyclomatic_complexity = []\n",
    "    nloc = []\n",
    "    parameter_count = []\n",
    "    method_name = []\n",
    "    token_count = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for index, row in src_code_df.iterrows():\n",
    "        #print('index{}'.format(index))\n",
    "        #print('type:{}'.format(type(row[code_column])))\n",
    "        metrics = lizard.analyze_file.analyze_source_code('java_file.java', row[code_column])\n",
    "        metrics_obj = metrics.function_list\n",
    "\n",
    "        valid_indices.append(index)\n",
    "        cyclomatic_complexity.append(metrics_obj[0].cyclomatic_complexity)\n",
    "        nloc.append(metrics_obj[0].nloc)\n",
    "        parameter_count.append(metrics_obj[0].parameter_count)\n",
    "        method_name.append(metrics_obj[0].name)\n",
    "        token_count.append(metrics_obj[0].token_count)\n",
    "    \n",
    "    src_code_df['cyclomatic_complexity'] = cyclomatic_complexity\n",
    "    src_code_df['nloc'] = nloc\n",
    "    src_code_df['parameter_count'] = parameter_count\n",
    "    src_code_df['method_name'] = method_name\n",
    "    src_code_df['token_count'] = token_count\n",
    "    \n",
    "    return src_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def heatmap(x, y, **kwargs):\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "        palette = sns.color_palette(\"Blues\", n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x10 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "    marker = kwargs.get('marker', 's')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order', 'xlabel', 'ylabel'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=[value_to_color(v) for v in color],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "\n",
    "    ax.set_xlabel(kwargs.get('xlabel', ''))\n",
    "    ax.set_ylabel(kwargs.get('ylabel', ''))\n",
    "\n",
    "    # Add color legend on the right side of the plot\n",
    "    if color_min < color_max:\n",
    "        ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "        col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "        bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "        bar_height = bar_y[1] - bar_y[0]\n",
    "        ax.barh(\n",
    "            y=bar_y,\n",
    "            width=[5]*len(palette), # Make bars 5 units wide\n",
    "            left=col_x, # Make bars start at 0\n",
    "            height=bar_height,\n",
    "            color=palette,\n",
    "            linewidth=0\n",
    "        )\n",
    "        ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "        ax.grid(False) # Hide grid\n",
    "        ax.set_facecolor('white') # Make background white\n",
    "        ax.set_xticks([]) # Remove horizontal ticks\n",
    "        ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "        ax.yaxis.tick_right() # Show vertical ticks on the right \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def corrplot(data, size_scale=500, marker='s'):\n",
    "    corr = pd.melt(data.reset_index(), id_vars='index').replace(np.nan, 0)\n",
    "    corr.columns = ['x', 'y', 'value']\n",
    "    heatmap(\n",
    "        corr['x'], corr['y'],\n",
    "        color=corr['value'], color_range=[-1, 1],\n",
    "        palette=sns.diverging_palette(20, 220, n=256),\n",
    "        size=corr['value'].abs(), size_range=[0,1],\n",
    "        marker=marker,\n",
    "        x_order=data.columns,\n",
    "        y_order=data.columns[::-1],\n",
    "        size_scale=size_scale\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
